### 什麼是Proof of Stake（權益證明機制）

權益證明機制是公有鏈共識演算法的一類，乙太坊接下來的 Casper 演算法是其中之一。它和比特幣、目前的以太坊及許多其他區塊鏈背後的Proof of Work有著相似的作用，但在安全性及能源使用效率上有著顯著的優點。

總的來說，權益證明機制演算法大致如下。區塊鏈記錄著一組 **validator** （驗證者），所有持有該區塊鏈數位貨幣的使用者（即以太坊的以太幣）都可藉由一個特殊交易將他們的數位貨幣鎖進一個存庫來成為驗證者。創造一個新的區塊的過程則藉由一個驗證者參與的共識演算法來進行。

目前有許多種的共識演算法及許多種獎賞驗證者的方式，因此有許多不同種類的權益證明機制。從一個演算法的角度，主要分為兩種： 鏈型態的權益證明機制 及 Byzantine Fault Tolerance（ BFT，拜占庭容錯）相似的權益證明機制。

在鏈型態的權益證明機制中，演算法在每個時間區間（例如每十秒為一區間）裡以偽隨機的方式選擇驗證者，並賦予其創造一個區塊的權利。而這個區塊如同區塊鏈，必須指向之前的區塊（通常是指向最長鏈的最新區塊），並隨時間拉長，成為單一條持續增長的鏈。

在拜占庭容錯相似的權益證明機制中，某個驗證者被隨機指派來_提議_（propose）新的區塊，每一輪每個驗證者將票（vote）投給特定的區塊，經過多輪投票來決定區塊是否有效。在過程結束之後，該區塊是否合法會達成永久的共識，即不會再改變。

### 權益證明機制在和工作量證明機制相比下有哪些優點？

詳細說明可見：[A Proof of Stake Design Philosophy](https://medium.com/@VitalikButerin/a-proof-of-stake-design-philosophy-506585978d51)裡有更完整的論述。 

簡短來說：
* 不需要為了達成鏈的安全而**消耗大量電力**，（估計以太坊和比特幣每天都會各消耗一百萬美元在電力及硬體成本上）。
* 因為不需要消耗大量電力，所以**沒有發行等量的貨幣的需要**來提供加入網路的動機。理論上甚至可以有淨量為負值的發行量--透過銷毀一部分的交易手續費的方式來達成。
* 權益證明機制提供了更多賽局理論的發揮空間，來**降低中心化組織的形成**，以及在組織已形成的情況下，可能的方法來防止他們進一步傷害網路（例如工作量證明機制中的[selfish mining](https://www.cs.cornell.edu/~ie53/publications/btcProcFC.pdf)）。
* **減少中心化造成的風險**。因為採用權益證明機制後，礦工（驗證者）要擴展規模將不會是個問題。在工作量證明機制中，當你資本多到一定程度，你可以負擔更好的規模生產設備，拉大和其他人的差距（投入一千萬的成本所獲得的收益不只是投入一百萬的十倍）。而在權益證明機制中，相比於一百萬貨幣，持有一千萬的貨幣會保證讓你獲得十倍的報酬，而且是以公平的方式。
* 可以利用經濟上的懲罰來**大大地提高不同51%攻擊方式在權益證明機制中所需要的成本**，引用 Vlad Zamfir 所述--"想像一參與51%攻擊你的ASIC工廠就會被燒毀"。

### 權益證明機制和傳統的拜占庭容錯研究怎麼結合？

拜占庭容錯研究中有一些重要的結論是適用到各種共識演算法中的，包含傳統的演算法如PBFT，同時也可用在任何權益證明機制中。如果搭配恰當的數學模型，甚至可以用在工作量證明機制中。

這些重要的結論包含：

* [**CAP 理論**](https://en.wikipedia.org/wiki/CAP_theorem) - "如果網路發生阻斷（partition）時，你只能選擇資料的一致性（consistency）或可用性（availability），無法兩者兼得"。論點很直覺：如果網路因阻斷而分隔為二，在其中一邊我送出一筆交易："將我的十元給A"；在另一半我送出另一筆交易："將我的十元給B"。則此時系統要不是 (1）無可用性，即這兩筆交易至少會有一筆交易不會被接受；要不就是 (2）無一致性，一半看到的是A多了十元而另一半則看到B多了十元。要注意的是，CAP理論和擴展性（scalability）是無關的，他在分片（sharded）或非分片的系統皆適用。

* [**FLP impossibility**](http://the-paper-trail.org/blog/a-brief-tour-of-flp-impossibility/) - 在非同步（asynchronous）的環境中（即兩個正常運作的節點間，網路延遲沒有上限），只要有一個惡意的節點存在，就沒有演算法能在有限的時間內達成共識。但值得注意的是，["Las Vegas" algorithms](https://en.wikipedia.org/wiki/Las_Vegas_algorithm)在每一輪皆有一定機率達成共識，隨著時間增加，機率會越趨近於1。而這也是許多成功的共識演算法會採用的解決辦法。

* 容錯的上限 - 由[ DLS 論文](http://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf) 我們可以得到以下結論： (1）在部分非同步（partially synchronous）的網路環境中（即網路延遲有一定的上限，但我們無法事先知道上限是多少），協議可以容忍最多 1/3 的拜占庭故障（Byzantine fault）。 (2）在非同步（asynchronous）的網路環境中，具 deterministic 性質的協議無法容忍任何錯誤，但這篇論文並沒有提及[ randomized algorithms](http://link.springer.com/chapter/10.1007%2F978-3-540-77444-0_7) 在這種情況可以容忍最多1/3的拜占庭故障。 (3）在同步（synchronous）的網路環境中（即網路延遲有上限且上限是已知的），協議可以容忍 100% 的拜占庭故障，但當超過 1/2 的節點為惡意節點時，會有一些限制條件。要注意的是，我們考慮的是"具認證特性的拜占庭模型（authenticated Byzantine）"，而不是"一般的拜占庭模型"；具認證特性指的是將如今已經過大量研究且成本低廉的**公私鑰加密機制**應用在我們的演算法中。

工作量證明機制 [已被 Andrew Miller 及其他人分析過](https://socrates1024.s3.amazonaws.com/consensus.pdf)，是一個仰賴同步的網路環境的模型。我們可以將網路設定為有接近無窮數量的節點，而每一個節點擁有非常小的算力，且在一定時間內有非常小的機率可以產生區塊。在這個設定中，假如沒有網路延遲存在，則此協議有 50% 的容錯率。經過觀察，以太坊有約 46% 而比特幣擁有約 49.5% 的容錯率，但如果網路延遲和產生區塊時間相當時，容錯率會降低至 33% ，若網路延遲趨近無限，則容錯率趨近零。

權益證明機制則是包含在拜占庭容錯共識模型中，因為所有驗證者皆是已知且系統會記錄驗證者的數量。權益證明機制的研究一般可分為兩個路線，一個是同步的網路環境模型，一個是部分同步的網路環境模型。鏈型態的權益證明機制演算法幾乎都仰賴同步的網路環境模型，而它們的安全性分析也都可用這些模型以相似於 [工作量證明機制](http://nakamotoinstitute.org/static/docs/anonymous-byzantine-consensus.pdf) 的方式來分析證明。另一個路線將部分同步網路環境中的傳統拜占庭容錯演算法和權益證明機制做連結，但解釋比較複雜，在後面的章節會有更深入的探討。

工作量證明機制演算法和鏈型態的權益證明機制演算法都偏好資料的**可用性**而非資料的**一致性**，但拜占庭容錯類的共識演算法更傾向於選擇資料的**一致性**，[Tendermint](https://github.com/tendermint/tendermint) 明確地選擇資料一致性的特質。而 Casper 則採用混合的模型，此模型偏好資料的可用性，但盡可能的確保資料的一致性，它讓鏈上的應用和使用者在任何時間都能知道當前資料的一致性有多大的保證。

Ittay Eyal 和 Emin Gun Sirer 的 [selfish mining 研究](https://bitcoinmagazine.com/articles/selfish-mining-a-25-attack-against-the-bitcoin-network-1383578440) 結論 - 在不同網路環境的模型中，比特幣挖礦的激勵兼容性（incentive compatibility）分別受到 25% 及 33% 的限制，即只有在 25% 或 33% 的礦工同謀不可能發生的前提下，挖礦的機制才是激勵兼容的（即礦工按照正常的方式挖礦：有多少算力獲得多少報酬）。這個結論和傳統的共識演算法的結論無關，因為傳統共識演算法的結論並沒有牽涉到激勵兼容性。

### 什麼是"無成本風險"問題及該如何解決這個問題？

在許多之前（鏈型態）的權益證明機制演算法，包含 Peercoin，只有對產生區塊給予相對應的獎賞但並沒有懲罰。這在出現多條相競爭的鏈（即分叉）的情況時，會有非預期的影響，因為每個驗證者皆有動機在每一條相互競爭中的鏈上產生區塊（以下將下注和產生區塊視為相同意思）來確保他們會獲得獎賞，如下：

![](https://raw.githubusercontent.com/vbuterin/diagrams/master/possec.png)

在工作量證明機制中，這麼做會導致礦工的算力被分散，導致獲利下降：

![](https://github.com/vbuterin/diagrams/blob/master/工作量證明機制sec.png?raw=true)

當給予區塊獎賞的同時卻沒有懲罰，結果就會造成 - 如果每個驗證者都是狹義上（narrowly）經濟理性的話，則即便在沒有任何攻擊者的情況下，區塊鏈本身也沒辦法達成共識。因為每個驗證者都在每條鏈上下注。如果有攻擊者，攻擊者只需要贏過那些執行利他行為（altruistic，即只會在單一條鏈下注）的節點即可，不需要贏過那些經濟理性的節點。相反的在工作量證明機制中，攻擊者必須要同時贏過利他節點和經濟理性節點（但這確實是可行的攻擊：參考 SchellingCoin 的 [P + epsilon 攻擊](https://blog.ethereum.org/2015/01/28/p-epsilon-attack/)）。

有些人會認為下注者有動機按照規則來下注且只下注在最長的鏈上，好讓他們的投資能夠保值。然而這個論點忽略了這個動機受制於公地悲劇理論（[tragedy of the commons](https://en.wikipedia.org/wiki/Tragedy_of_the_commons)）：每個下注者可能只會有 1% 的機會成為關鍵（pivotal）的角色（即他的決定會影響一個攻擊的成敗），所以用來買通他們的賄絡金額只需要是他們總賭注金額的 1% 。因此，全部的賄賂金額只需要是下注總額的 0.5-1% 。此外，本段開頭的論點同時暗示著任何"不可能失敗"的情況都不是一個穩定的平衡，因為不可能失敗的情況代表每個下注者成為關鍵角色的機會是零，即只要賄賂金額超過 0% 都能讓下注者有動機參與攻擊。

有兩種方式可以解決這個問題。第一個為 "Slasher"，在[這篇文章](https://blog.ethereum.org/2014/01/15/slasher-a-punitive-proof-of-stake-algorithm/)有大略地描述，並進一步由 [Iddo Bentov ](https://arxiv.org/pdf/1406.5694.pdf)開發。當驗證者同時在不同條分叉的鏈上下注（產生區塊）的情況發生時，將證據紀錄進區塊鏈中並以此銷毀驗證者的下注資本。這讓動機結構改變如下：

![](https://github.com/vbuterin/diagrams/blob/master/slasher1sec.png?raw=true)

注意，這個演算法要能執行，**驗證者是哪些人**需要事先就知道。否則驗證者可以任意選擇要下注的鏈：即當A鏈可下注就下注A鏈，當B鏈可下注就下注B鏈，當兩條都可以下注就下注最長的鏈。所以事先確定驗證者的名單可以避免這種情況發生。但這也有缺點存在，包括要求節點需要頻繁地上線來獲得安全可信的鏈的狀態（即確認區塊是不是由合格的驗證者所產生），並且讓 medium-range 的驗證者共謀攻擊有可能發生（例如連續三十個驗證者中有25個預謀發起攻擊來回復過去19個區塊），因為驗證者事先知道什麼時候會輪到他產生區塊。如果這些風險是可接受的那就沒太大問題。

第二個方式單純地懲罰在錯的鏈產生區塊的驗證者。也就是當有兩個互相競爭的A和B鏈，如果有一個驗證者在B上面產生區塊，則他可在B鏈上獲得 R 的獎賞，但這個區塊的標頭（header）資料會被記錄在A鏈上（在 Casper 中叫做 "dunkle" ）且他在A鏈上會受到 F 的罰金（ F 可能等於 R ）。這會將結構改變成：

![](https://github.com/vbuterin/diagrams/blob/master/slasher2sec.png?raw=true)

直覺來說，我們可以把工作量證明機制的經濟模型複製到這來用。在工作量證明機制中，在錯的鏈上產生區塊同樣有懲罰，但這個懲罰並不顯而易見：礦工額外的電力或硬體成本花費（因為要同時在兩條鏈上花費運算）。第二個方式的一個缺點是，它將些微的風險加注到驗證者身上（因為驗證者要承擔在錯的鏈上產生區塊的成本），不過這個風險會隨者時間慢慢減退，但另一方面，它的優點是不需要事先知道驗證者有誰。

### 上一章節介紹鏈型態的權益證明機制如何解決"零風險成本"問題，那拜占庭容錯相似的權益證明機制又是怎麼運作的呢？

拜占庭容錯類型（部分同步的網路環境）的權益證明機制演算法允許驗證者藉由送出遵守兩類別規則的簽名訊息，來對區塊進行"投票"，這兩類規則分別是：

* **終局條件（Finality conditions）** - 規則用來決定某雜湊值是否可被視為不可更改的（finalized）。
* **刪砍條件（Slashing condition）** - 規則用來決定是否有足夠理由懷疑某個驗證者作弊（例如同時下注多個相衝突的區塊）。

如果有驗證者觸發其中任何一條規則，他們的資本將全數被刪去。

以下舉兩個例子來說明不同刪砍條件的發生場景，下面的" 2/3 的驗證者" 代表 "全數驗證者資本總和的 2/3，而不是驗證者數量的 2/3 "，其他的比例亦相同。在這些例子中，"PREPARE" 和 "COMMIT" 可單純地理解為兩種驗證者可送的簽名訊息（`MESSAGE`）。

1. 如果`MESSAGE`包含：`["COMMIT", HASH1, view]` 和 `["COMMIT", HASH2, view]`，其中`view`為相同但`HASH1`和`HASH2`不同，且皆由同一個驗證者所簽名，則該驗證者的資本被刪去。即不能同時對相衝突的區塊做簽名。
2. 如果`MESSAGE`包含：`["COMMIT", HASH, view1]`，則**除非** `view1 == -1` ，或同時存在其他包含`["PREPARE", HASH, view1, view2]`的簽名訊息（其中 `view2 < view1`）且這些訊息由至少 2/3 的驗證者所簽名，則對`"COMMIT"`簽名的驗證者的資本被刪去。即一個 `HASH` 值只有經過至少 2/3 `PREPARE` 才能被 `COMMIT`。

合適的刪砍條件需要有兩個重要的要求：

* **可咎責的安全性（Accountable safety）** - 如果相互衝突的`HASH1` 和 `HASH2`（即分叉）都被認定為不可更改，則至少有 1/3 的驗證者肯定違反了某些刪砍條件。
* **Plausible liveness** - 除非至少 1/3 的驗證者違反了某些刪砍條件，否則必定存在某些合法的訊息是 2/3 的驗證者可以簽的，且這些訊息會讓某些雜湊值變成不可更改（finalized）。即除非至少 1/3 的驗證者違規，否則一定可以讓新的雜湊值被 finalize。

如果我們有一組刪砍條件可以達成這兩個要求，我們便可以提供驗證者足夠的動機，並開始從 economic finality 的特性中得到成果。

### 一般來說，什麼是"經濟面上終局的特性"？

經濟面上終局指的是：當區塊被認定為不可更改，或更一般來說，有一種訊息獲得足夠數量的簽名，則唯一讓鏈在未來納入另一個相衝突的區塊的方法是有一大群的人願意賠上一大筆錢。如果一個節點看到某個區塊符合經濟面上終局的特性，則他有經濟面上非常大的保證這個區塊會成為鏈的一部分歷史（且這條鏈也是大家都認可的）。

達成經濟面上終局有兩種方法：

1. 如果有足夠多的驗證者對以下形式的聲明進行簽名，則一個區塊可被視為具有經濟面上的終局："當區塊B沒有被收入則我會失去X的資本"。這讓使用者獲得了如下的保證 - (I)區塊B是鏈的一部分，或是 (II)若驗證者想騙他們，讓他們相信區塊B是有被收入的，則驗證者會損失一大筆錢。

2. 如果有足夠多的驗證者簽名表達支持收入區塊B，而且有方式能在驗證者違規時提出數學證明（_當不同於區塊B的某區塊B'也以同樣方式被收入_）並讓這些驗證者損失一大筆錢，則一個區塊可被視為經濟面上的不可更改。如果使用者看到這個被收入的區塊，並驗證了鏈的有效性，且藉由有效性（validity）和不可更改性（finality）他們可以在發生分叉的鏈之中做出選擇，則他們能獲得如下的保證 - (I)區塊B是鏈的一部分，或是 (II)若驗證者同時也參與了另一條互相競爭且亦符合終局條件的鏈，則驗證者會損失一大筆錢。

兩種達成終局（finality）的方法分別繼承自"零風險成本問題"的兩個解決方法： 藉由懲罰錯誤（如`"COMMIT"`不合法的區塊）來達成終局 及 藉由懲罰不明確性（如`"COMMIT"`兩個衝突區塊）來達成終局。第一個方法的主要優點是輕客戶端（light client）使用者也能驗證且比較直覺易懂；第二個方法的主要優點有 (I)比較容易瞭解為何誠實的驗證者不會被懲罰及 (II)干擾因素（griefing factors）對誠實的驗證者比較有利 - 相比於不誠實者干擾誠實者所要付出的成本，誠實者干擾不誠實者的成本是比較低的。

Casper 遵循第二種方法。不過可以透過增加鏈上的機制，讓驗證者可以自行選擇是否要對第一種方法的聲明（"當區塊B沒有被收入則我會失去X的資本"）簽名，此舉可讓更多輕客戶端使用者增加效率。

### 所以這和拜占庭容錯理論有什麼關聯？

傳統的拜占庭容錯理論在 safety 和 liveness 上和我們有相似的要求。首先，傳統拜占庭容錯理論要求當超過 2/3 的驗證者是誠實的時候，safety必須要被達成。嚴格來說這是比較容易實現的模型，傳統的拜占庭容錯理論嘗試證明"如果共識機制無法達成safety，則我們知道至少有 1/3 的驗證者是惡意的"；而我們的模型則是嘗試證明"如果共識機制無法達成safety，則我們知道至少有 1/3的驗證者是惡意的，而且我們知道是哪些驗證者，即便你在出現問題的當下不在線上"。從liveness的角度，我們的模型比較容易達成，因為我們不需要證明**共識會被達成**，我們只需要證明機制**沒有卡住**。

不過幸運的是，額外的"可咎責的"（accountable）特性需求其實不難實現；事實上，只要協議有正確的防禦機制（protocol armor），我們都可以將任何不管是部分同步或是非同步的傳統拜占庭容錯演算法轉換成可咎責的演算法。這個證明基本上歸結於一個事實--拜占庭故障（fault）可以被窮舉並分類，而這每一類要不是 (I)可咎責的（如果你`"COMMIT"`了這類的訊息，則你會被逮到，且我們可以為此建立一條刪砍條件的規則），要不就是 (II)無法被分辨是網路延遲還是故障（注意，即便是太早送出訊息這種故障，也沒辦法被分辨出來）。

### 什麼是弱主觀性（weak subjectivity）？

首先很重要的一點是，利用存款（deposit，也就是驗證者加入的資本）來確保"風險成本不為零"的機制，改變了權益證明機制的安全模型假設（security model）。假設 (I)存款會被鎖住一個月，時間到之後可以提走， (II)有個 51% 攻擊嘗試反轉（revert）長達 10 天的交易量，則這些攻擊者產生的區塊會被寫入鏈裡當作證據且驗證者會被懲罰。然而，假設攻擊變成長達 40 天，則雖然這些攻擊產生的區塊可以再被寫入鏈裡，但驗證者早已能把錢提走而不會受到懲罰。為了要解決這個問題，我們需要一個"反轉限制（revert limit）"的規則，也就是當反轉所影響的區塊總時間長度超過存款鎖住的期限，則節點可以拒絕接受這些區塊（在上例，即拒絕影響超過一個月的反轉區塊）。這表示節點現在多了兩項要求：

1. 當節點第一次連上並要同步鏈的資料的時候，他們必須藉由鏈外的方式來驗證最新的狀態，即透過朋友節點們或各個 Block Explorer 等等的方式。如果他們得到的都是同一條一樣的鏈，則可以確定這條是正確的。注意，只有在出現鏈分叉長度超過反轉限制時（在上例，即得到兩條在過去超過一個月的區塊皆不相同的鏈）才需要這種採用這種鏈外的交際驗證（social authentication）。

2. 節點每隔一段的時間（"反轉限制"時間）就必須要上線同步。如果沒定時同步，則需要再透過一次鏈外的交際驗證來保證狀態的可信度。

如果攻擊者要利用鏈外交際這個管道來攻擊，他們必須要說服社群裡一大部分的人，讓他們相信攻擊者的鏈才是有效的；或是改為說服新加入社群的人：新加入的人可能會在下載軟體時一並收到最近一次的檢查點（checkpoint，即反轉限制的臨界點），但如果攻擊者能竄改這個檢查點的紀錄，則他們要能直接竄改整個軟體也不再是件難事，而且沒有單純的密碼經濟學的驗證方式能解決這個問題。當一個節點連接上了，只要他夠頻繁地上線，他就能以密碼經濟學上安全的模型來確保連接上正確的鏈，而不需要額外的鏈外交際驗證。

另外，這種交際驗證如果需要，也可以直接加入進使用者使用的過程中：如 (1)[BIP 70](https://github.com/bitcoin/bips/blob/master/bip-0070.mediawiki)的交易就要求交易裡要加入最近一段時間的某個區塊的雜湊值，使用者的軟體會在交易成立前，藉此確保使用者和商家是在同一條鏈上（也可以透過其他鏈上的互動方式）。 或(2)，採用Jeff Coleman的 [universal hash time](https://www.youtube.com/watch?v=phXohYF0xGo)。採用UHT的話，如果攻擊要能成功，攻擊者必須在被攻擊鏈繼續增長的**同時**，暗中產生另一條鏈（即攻擊者沒辦法事先或在事後短時間內產生一條相抗衡的鏈），代表這需要大多數的驗證者共謀了一段非常長的時間。

### 在權益證明機制裡可以用經濟上的方式來懲罰審查（censorship）行為嗎？

審查行為比起交易反轉要更難去證明。區塊鏈本身無法分辨 (1)"使用者 A 嘗試送出交易 X 但被審查過濾掉了" 或是 (2)"使用者 A 送出交易 X 但因為交易費不夠而沒被收入區塊裡" 或是 (3)"使用者 A 從未送出交易 X "。但仍有一些方法可以對抗審查行為。

第一個是使用停機問題（halting problem）。這個方法比較弱的版本是將協議設計成圖靈完備，使得驗證者無法知道一筆交易會不會在花費他大量的運算後因為出現預期外的行為而出錯，但這同時也讓驗證者面臨潛在的 DoS 攻擊。這也是當初[ the DAO 軟分叉](http://hackingdistributed.com/2016/07/05/eth-is-more-resilient-to-censorship/)沒有實行的原因。

比較強的版本則是讓交易在未來中短期的時間內觸發特定的效果。使用者可以送出多筆相互關聯的交易及利用可預期的第三方的資訊來導致未來事件的發生，想要進行審查的驗證者要等到交易都被收入區塊（並確認為不可更改）才能知道發生了什麼事件，但此時要阻止交易又已經太遲。即便過濾掉所有相關的交易，審查者想阻止的事件還是會發生。審查者可以試著過濾掉每一筆交易，或是過濾掉沒有附上相關證明（證明交易不會導致任何非預期的情況發生）的交易，但這麼做會擋掉非常多不同類型的交易以至於讓整個系統失靈，審查者的存款價值也會跟著該數位貨幣的價值崩盤而下降。

第二個方法是（[如 Adam Back 在這篇文章](https://www.reddit.com/r/Bitcoin/comments/4j7pfj/adam_backs_clever_mechanism_to_prevent_miners/d34t9xa)）所介紹，要求交易都經過[timelock-encrypted](https://www.gwern.net/Self-decrypting%20files)加密。所以審查者只能在不知道交易的內容的情況下將交易收入區塊，直到之後某個時間點交易內容被揭露，但此時要過濾掉交易已經太遲。但是審查者可以選擇只收入有附上解密證明（如利用 zkSNARK 等零知識證明）的交易；這雖然會強迫使用者必須要去下載相關的使用軟體，但審查者可以直接提供所需軟體。這在賽局理論中，使用者是有動機去配合的。

或許在權益證明機制中比較好的做法是使用者透過軟體更新來執行硬分叉，將惡意的驗證者移除。這個方法和下載解密軟體來配合審查的方法相比，並沒有多難。總之，第二個方法雖然會降低和鏈溝通互動的速度（注意，採用這個方法必須是強制的才會有效，否則審查者只需要過濾掉經過加密的交易並收入沒加密的交易即可），卻也是比較適度且有效的。

第三個方法是在鏈分叉發生時，將偵測審查行為發生的機制加進分叉選擇的考量。原理很簡單，節點持續觀察著網路及交易，如果他們發現某筆交易帶有夠多的手續費卻遲遲未被收入，就給沒有收入這筆交易的鏈較低的評分。如果所有的節點都遵守這規則，則最終較弱勢的鏈也會因為收入了這個交易而讓其他誠實的節點都轉而加入這條鏈。這個方法主要的缺點是，離線的節點還是紀錄者強勢的（有審查機制的）鏈，如果在他們重新上線之前審查行為就結束了，則會造成上線的（誠實的）節點間的分歧。因此這個方法比較適合被用來當作緊急情況如硬分叉發生時的一個節點間的協調工具，如果是用在幾乎每天都會發生的鏈分叉選擇考量則不太合適。

### 驗證者是怎麼選出的？什麼又是stake grinding？

在任何鏈型態的權益證明機制演算法中，都需要一個機制來隨機選出哪個驗證者可以產生下個區塊。例如，假設目前活躍中的驗證者包含 資本為 40 元的的 Alice、資本為 30 元的 Bob、資本為 20 元的 Charlie 及資本為 10 元的 David，則你希望他們各自被選出的機率分別為 40%、30%、20%及10%（當然在實際情況中，你會希望選出來的是一連串無限的候選人而不是一個，這樣當前面一位沒出現，後面一位就可以遞補，但這不影響根本的問題）。在非鏈形態的演算法中，一樣會因為不同原因而需要隨機性（randomness）。

"Stake grinding"是一種驗證者試圖透過一些計算或其他方式來影響隨機性的攻擊。例如：

1. 在 [Peercoin](https://bitcointalk.org/index.php?topic=131901.0) 中，驗證者可以搜尋各種參數的組合並找到特定的參數來增加他們產生有效區塊的次數。

2. 在一個目前已經不使用的方式裡，第 N+1 個區塊的隨機性取決於第 N 個區塊裡的簽章。這讓驗證者可以重複產生新的簽章直到他們找到一個特別的簽章來讓他們能預測並掌握下一個區塊，以藉此控制系統。

3. 在 NXT 中，第 N+1 個區塊的隨機性取決於產生第 N 個區塊的驗證者。這讓驗證者可以藉由跳過一個產生區塊的機會來操縱隨機性。雖然這麼做的機會成本是損失一個區塊獎賞，但有時候新產生的隨機種子可以讓驗證者在未來數十個區塊中獲得高於平均區塊獎賞的獎勵。[這裏](http://vitalik.ca/files/randomness.html)有更詳細的分析。

\#1和\#2很容易解決；一般的做法是要求驗證者事先存款來避免驗證者一直改變身份（address）來找到可以影響隨機性的值，並避免使用可以輕易被操縱的訊息，例如一個區塊裡的簽章。有幾個主要的策略來解決\#3。第一個是利用 [secret sharing](https://en.wikipedia.org/wiki/Secret_sharing) 或是 [deterministic threshold signatures](https://eprint.iacr.org/2002/081.pdf) 並要求驗證者一同產生隨機值。這些方法在大多數驗證者沒有同謀的時候都足夠穩固（看各種應用不同，33%-50% 的驗證者合謀就可以干預，使得協議對維持 liveness 的機率假設剩下 67% ）。

第二個方法是使用密碼學的方式：驗證者事先 commit 一些訊息（如公布 `sha3(x)`），接著在區塊內公佈 `x` 值，最後將 `x` 值和其他人的隨機值加在一起。理論上針對這個方法有兩種潛在的攻擊。

1. 在commit時操縱 `x` 值。但因為結果會將許多人的 `x` 值一起加入考量，其中只需要一個人是誠實的，隨機性的分佈就會呈常態分佈，所以這攻擊不太可行。

2. 選擇性地不公開區塊。這種攻擊的機會成本是損失一個區塊獎賞，而且這個方法頂多只能讓一個人看到下一個區塊的驗證者是誰，所以最多可能的獲益也是一個區塊獎賞。唯一的例外是，如果一個驗證者跳過，則遞補上來的驗證者和下一個區塊的驗證者有可能會是同樣一個驗證者。可以用懲罰的方式來抵消驗證者跳過的動機。

第三個方法是使用 [Iddo Bentov 的 "majority beacon"](https://arxiv.org/pdf/1406.5694.pdf)，藉由之前產生的（也用 beacon 方式產生的） N 個隨機數字中的每個 bit 值的多數決來產生新的隨機數字（即，如果大多數數字的第一個 bit 為 1 ，則新的數字的第一個 bit 為 1 ，否則為 0 ）。攻擊的成本會是 `~C * sqrt(N)` ，其中 C 是攻擊其他 beacon 產生的隨機數字的成本。總之，有許多 stake grinding 的解決方法存在，這個問題比較像是 [differential cryptanalysis](https://en.wikipedia.org/wiki/Differential_cryptanalysis) 而不是 [halting problem](https://en.wikipedia.org/wiki/Halting_problem) - 權益證明機制的設計者最終會明瞭且會知道如何克服，不是很根本且無法彌補的缺陷。

### 針對 Casper 的 51% 算力攻擊會是怎麼樣的攻擊？

51% 攻擊最基本的形式就是 **finality reversion**：驗證者確立區塊 A 的紀錄為不可更改後又將另一個區塊 A' 也列為不可更改，打破區塊不可更改特性的保證。在這個情況中並存著兩個彼此不相容的歷史紀錄，導致鏈產生分叉。這需要仰賴社群以鏈外的方式進行協調來決定應該選擇哪條鏈，而哪條該被捨棄。

協調的管道有很多種，如社群媒體、block explorer 及交易所間的溝通、線上論壇等等。決定該選哪條鏈的原則是 "哪條先出現就選哪條" 。另一個方式是讓市場機制去決定：在很短的時間裡，兩條分叉都可以在交易所中交易，直到其中一條因為價值更高而勝出。在這種情況中，"哪條先出現就選哪條" 的原則會是市場機制的 [Schelling point](https://zh.wikipedia.org/wiki/谢林点)，即參與者會因為覺得其他人也會選擇先出現的那條鏈而傾向選擇先出現的那條，所有人在沒有溝通的情況下按照這個傾向選擇了先出現的那條鏈。所以實際中，這兩種方式並用是非常有可能的。

當該選擇哪條鏈的共識達成時，使用者（即驗證者、light node 及 full node）就可以手動地將勝出區塊的雜湊值藉由特殊的選項寫入軟體中，之後他們的節點就會忽略其他不包含該雜湊值的鏈。之後不管是哪條鏈被選擇，都有證據可以用來懲罰至少 1/3 的違規驗證者。

另外一種攻擊是阻斷 liveness：一個由超過 34% 驗證者組成的集團可以拒絕和其餘的驗證者合作。在這種情況下，將沒有區塊能被變成不可更動。Casper 採用混合（鏈 + 拜占庭容錯）型態的共識，因此鏈還是會持續增長，但安全性會大大降低（因為一直沒有新的區塊可以被視為不可更改）。如果很長一段時間（例如一天）都沒有區塊變成不可更改，則有以下幾種選項：

1. 可以採用一個自動化的功能來輪轉驗證者名單，瓦解集團的佔比。在新的驗證者名單中區塊有機會被變為不可更改，但使用者會收到提醒告訴他們這些不可更改的區塊還是不能全信的，因為很有可能舊的一組驗證者會重新奪回控制權並改為將其他的區塊變為不可更改。使用者如果確信舊的一組驗證者不會再上線，就可以忽略這些警告。在這種情況發生時，所有舊的驗證者如果沒有再繼續參與共識過程，則他們會受到相當大筆的罰款。

2. 採用硬分叉的方式移除集團驗證者的存款，並增加新的驗證者。

在第二種方法中，分叉還是一樣要由鏈外的共識來協調，且可能會由市場機制的方式（即兩條擁有不一樣驗證者組成的鏈短暫的並存於交易市場上）。如果是藉由市場共識的方式，有個有力的論點是：市場會傾向選擇 "好人勝出" 的鏈，這條鏈的驗證者展現了他們的誠意（或至少他們和使用者的利益是並存的），因此也是一條對應用開發者較有用的鏈。

選擇攻擊應對的策略如社交協調或機制內自動化，兩者之間其實有如一道光譜，並不是非黑即白。通常設計越往自動化的解法越理想，因為這可以降低當 51% 攻擊和社交層面（包含市場共識如交易所）的攻擊同時發生時的風險。可以想像一個採用 \#1 的措施：節點在超過一定時間都沒有區塊變為不可更改時自動更換驗證者名單，這會降低交際協調的需要，但節點也因此要更頻繁地保持上線。但不管是哪種方式，攻擊者都會損失一大筆的錢。

另外一種比較不容易發覺的攻擊是審查攻擊：超過 34% 的驗證者拒絕將含有某些特定交易的區塊變為不可更改，除此之外鏈的運作都正常。攻擊的範圍從輕微的，干擾特定應用的攻擊（如過濾 Raiden 或閃電網路的交易是較簡單偷錢的方式）到阻擋所有交易的大範圍攻擊。

其中又分成兩種情況，第一個是攻擊者佔 34%-67%。在這種情況中，正常的驗證者可以拒絕將他們主觀認定為正在過濾交易的區塊（即攻擊者產生的區塊）變成不可更改或接在後面，這讓這種攻擊變為一個標準的針對 liveness 的攻擊。比較危險的情況是當攻擊者佔超過 67%，攻擊者可以任意的阻擋他們不喜歡的交易並拒絕接在包含這些交易的區塊後面。

面對這個攻擊有兩道防線。第一，以太坊具有圖靈完備特性，[在本質上就具有抵抗審查的能力](http://hackingdistributed.com/2016/07/05/eth-is-more-resilient-to-censorship/)，因為審查交易的過程在某種程度上相似於解決停機問題（halting problem）。但因為區塊有 gas 限制，所以審查並不是不可能，不過用"簡單"的方式來審查反而會讓攻擊者自己有被 DoS 的風險。

單純具有這個抵抗能力[還不夠好](https://pdaian.com/blog/on-soft-fork-security/)，還有其他方式可以加強抵抗審查的能力。最有趣的方式是增加一個機制內的功能：讓交易能自動規劃未來的事件，因為預測一個事件的執行結果或是連鎖事件是很難的。驗證者可以藉由混淆事件規劃的順序來加入成為驗證者，藉此稀釋攻擊者的佔比到低於 33% 。

第二，引進 "active fork choice rule" 的概念：當面臨鏈分叉，其中一個選擇鏈的考量是和鏈進行互動並藉此驗證該鏈是否有在過濾你的交易。最有效的方式是節點重複地送出一筆交易來規劃下注並在最後一刻取消。如果節點偵測到審查機制，就不取消交易並暫時加入成為驗證者之一，將攻擊者的佔比稀釋到 33% 。如果集團過濾掉他們的交易，則採用這個 "active fork choice rule" 的節點就不會選擇這條鏈。這會讓審查攻擊轉變為 liveness 攻擊，此時就可以藉由解決 liveness 攻擊的方式來處理。

### 聽起來似乎很仰賴鏈外的社交協調，這樣難道不危險嗎？

攻擊 Casper 代價非常高。以下我們將會講到，攻擊 Casper 的代價至少和買礦機持續不斷的對採用工作量證明機制的鏈發動 51% 攻擊直到無效果為止的代價一樣。因此，上面段落所描述的復原方法只有在非常極端的情形才會用到。事實上，工作量證明機制的提倡者亦表達在某些相似情況採用社交協調的意願，例如[改變工作量證明機制的算法](https://news.bitcoin.com/bitcoin-developers-changing-proof-work-algorithm/)。所以權益證明機制需要的社交協調是否會比工作量證明機制所需要的社交協調還多還無明確的結果。

在現實中，我們預期用到社交協調的方式的次數會接近零次，因為攻擊者會瞭解到單純為了讓區塊鏈停擺一兩天要花費這麼大筆的錢是不符利益的。

### 邊際成本趨近邊際收益不就表示所有具有一定高度安全層級的共識演算法都一樣有效（或一樣地浪費）？

許多人都提出過這個論點，而解釋最清楚的就屬[Paul Sztorc 的這篇文章](http://www.truthcoin.info/blog/工作量證明機制-cheapest/)。其中的重點大概是：如果你創造一個有 100 元獎賞的機會，則大家為了得到它會願意花費最高到 99.9 元（包含自己付出的勞力），此時邊際成本趨近邊際效益。因此，這個理論說：任何提供區塊獎賞的演算法（不管是權益證明機制或工作量證明機制），其中為了獲取獎賞而進行對社會無效益的活動的數量都是一樣的，即它們都一樣地浪費資源。

這個理論有三個盲點：

1. **單純地說邊際成本趨近邊際效益是不夠的，必須還要假設一個真的有人可以花費那些成本的機制存在。** 例如，假設我明天宣布未來每一天我都會隨機從一個十人名單中挑出一個人並給予他 100 元，然而沒有人有辦法花費 99 元來取得其中的隨機值。他們要不是不在名單中拿不到獎賞，要不就是在名單中但沒有任何有效的方法取得我的隨機值，只能獲得期望值為平均每天 10 元的獎賞。

2. **邊際成本趨近邊際效益不表示總成本趨近總收益。** 例如，假設存在一個演算法利用偽隨機（pseudo-randomly）的方式從一大群驗證者中選擇 1000 位驗證者(一個驗證者獲得 1 元獎賞)。如果你資本佔總資本的 10% 則你平均會獲得 100 元。假設你可以花費 1 元來（無限次地）重設隨機值，因為 [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)，你可獲得的獎賞的標準差是 10 元，又因為[其他已知的數學結論](http://math.stackexchange.com/questions/89030/expectation-of-the-maximum-of-gaussian-random-variables)， N 個隨機抽樣中最大的期望值約略小於 ` M + S * sqrt(2 * log(N))` ，其中 M 是中間值且 S 是標準差。因此增加重設隨機值的次數（即增加 N ）所獲得的獎賞會快速地下降，例如如果完全不嘗試重設隨機值你的期望獲利是 100 元，嘗試一次是 105.5 元，兩次是 108.5 元，三次是 110.3 元，四次是 111.6 元，五次是 112.6 元，六次是 113.5元（只增加 0.9 元的獲利）。因此嘗試超過五次之後就不值得再繼續嘗試。所以一個由經濟因素所驅動的攻擊者，如果他總資本佔 10% ，則他會花費 5 元嘗試重設隨機值來獲得額外的 13 元的獲利，雖然這麼做很沒效率。如果一個機制可被有心人士利用，但被利用的機率不高，則損失不會多。但這不適用於在工作量證明機制中因為出現一個漏洞而導致全部資源投入而造成浪費的情況。而這點也和下一章節要介紹的 capital lockup costs 非常相關。

3. **權益證明機制要變得安全穩固所需要的獎賞比起工作量證明機制的獎賞少的非常多。**

### 什麼又是 capital lockup costs?

將 X 數量的 ether 鎖進存庫是有代價的，例如犧牲選擇其他選項的機會。如果我有 1000 ether，我想怎麼使用就怎麼使用，但如果我將它鎖在存庫裡數個月，而且沒有保險來支付可能的意外支出的時候該怎麼辦？在這段時間我同時也失去將 ether 轉換成其他代幣的自由。我可以透過賣空相等數量 ether 的方式來模擬賣掉我的 ether，但會有交易手費續和利息的成本。有些人可能會認為： captital lockup 造成的經濟上的不便和工作量證明機制造成的經濟層面上無效率的程度是一樣的。但答案是否定的，如同上一章節的理由\#2和理由\#3。

我們先從理由\#3開始講起。考慮一種模型：權益證明機制存款是無限期的、ASICs可以永久持續運作、ASIC技術固定（即不適用摩爾定律）而且電力花費是零，並假設穩定的利率是每年 5%。在工作量證明機制裡，我花 1000 元買了礦機，礦機每年給我 50 元的利潤直到永遠。在權益證明機制中，我存 1000 元（因為存款是無限期的所以這筆錢當作花掉）並獲得每年 50 元的利潤直到永遠。到目前為止，兩種情況看起來是等價的（雖然技術上來說，在權益證明機制中當我的存款因違規被銷毀時，會間接造成其他人的存款價值升高，但這邊我們先不討論）。在這個假設下，不管是權益證明機制或工作量證明機制，任何人要發動 "Maginot-line" 51% 攻擊（即硬體買得比網路其他人加起來還多）的成本都會因為我的加入而再多上 1000 元。

現在假設模型依序做以下的變更：

1. 摩爾定律適用，ASICs 每 2.772 年貶值 50%（為方便計算，假設其價值每年持續降低 25%）。如果我要繼續保持 "付一次，永遠都能持續拿回錢" 的模式，我可以將 1000 變成一筆資金，其中167用來買 ASICs ，833 元花在 5% 報酬率的投資。833元的投資產生每年 41.67 元的利潤剛好足夠花在更新 ASICs 設備上（為方便計算，假設技術發展是穩定連續的）。這時挖礦的利潤會降低至 167 * 0.05 = 每年 8.33 元，因此 83.3% 的礦工會退出競爭，直到回到每年 50 元利潤的穩定狀態，所以這時發動 Maginot-line 51% 攻擊的成本會縮小至少六倍。

2. 電力加上硬體維護組成大約 1/3 的挖礦成本。1/3 是從最近的數據估計而來的：Bitfury 的新資料中心 [每 gigahash 電力消耗為 0.06 焦耳 ](http://www.coindesk.com/bitfury-details-100-million-georgia-data-center/)，或 每 terahash 60 焦耳、每terahash 0.000017千瓦小時。如果假設比特幣網路的平均消耗皆如此的話，以[比特幣總共算力約 1.67 million TH/s](http://bitcoinwatch.com/) 來算，每秒約消耗 27.9 千瓦小時。中國電力成本為[每千瓦小時 0.11 元 ](http://www.statista.com/statistics/477995/global-prices-of-electricity-by-select-country/)，約為每秒 3 元或每天 26 萬元。比特幣區塊獎賞加上手續費為 600 * 13 * 144 = 一天 112 萬元。因此電力組成約 23% 的成本，另外我們可以用簡單的計算預估硬體維護成本為 10% 。這表示你的 1000 元資金裡，只有 111 元要拿來買 ASICs，55 元要拿來付持續性的花費如電力和維護等，而 833 元會花在投資上，因此現在要發動 Maginot-line 51% 攻擊的成本已經是一開始的至少九倍小了。

3. 事實上存款是短暫而非永遠（被視為拿不回來）的，當然你自願永遠存著的話也行。這讓我多了一些空間選項，我可以在任何時間內結束並等待一段時間（如四個月）。這表示我願意花更多的錢來獲得更多的利潤（因為投資不會再被當作拿不回來的錢），或許是 3000 元。因此，在權益證明機制裡發動 Maginot line 51% 攻擊的成本增加為原本的三倍，和工作量證明機制比起來是 27 倍的安全性。

以上包含了很多簡化過的計算，但它的目的是為了指出經過許多因素考量，都顯示出權益證明機制有更高的安全性。而這個[看似可疑的多重因素論點](http://lesswrong.com/lw/kpj/multiple_factor_explanations_should_not_appear/)為何這麼強烈凸顯權益證明機制的優點的主要理由是：在工作量證明機制中，我們操作並利用物理特性；而在權益證明機制中，我們可以設計出一套準確具有理想特性的機制 - 簡而言之，我們可以用我們的方式來優化 "物理特性"。在安全模型上的改變，特別是弱主觀性（weak subjectivity）這個性質的出現，讓我們能得到以下結論 - **權益證明機制要變得安全穩固所需要的獎賞比起工作量證明機制的獎賞少的非常多。**。

接者我們可以討論 邊際成本/效益 和 總成本/效益 的不同。在 capital lockup costs 的情況中這非常重要。例如假設一個情況，你有價值 100000 的 ether。鎖住其中的 50000 應該不會有什麼問題，鎖住 80000 可能會有一點不方便雖然 20000 還是夠充足，鎖住 90000 就有點問題了，99000 問題就大了，全鎖住那你可能是瘋了，因為你會連交易費都出不起。因此你的邊際成本快速的增加，我們可以用以下方式比較權益證明機制情況和工作量證明機制情況的不同：

![](https://blog.ethereum.org/wp-content/uploads/2014/07/liquidity.png)

可以看到在權益證明機制的總成本是遠小於存入 1 ether 的邊際成本乘上現有所有的存款總量。

注意，這部分的論點可惜地並沒有完全解釋到 "貨幣的安全發行量（safe level of issuance）"。但其顯示出即使我們將貨幣發行量控制地很低，我們還是能獲得可觀的 權益證明機制參與人數，雖然這也代表很大一部分的發行量會被用來獎賞驗證者。

### 在權益證明機制的礦池會有類似工作量證明機制礦池中心化的風險嗎？

從 [Bitcoin](https://blockchain.info/pools) 和 [Ethereum](https://etherscan.io/stats/miner?range=7&blocktype=blocks) 來看，大約需要三個礦池聯合才能發動 51% 攻擊（ 在寫這篇文章的時候，Bitcoin 約需四個、Ethereum 約需三個）。假設在權益證明機制中，包含所有礦池、交易所一共有 30% 的參與率，則 [三個礦池或交易所](https://etherscan.io/accounts) 就足夠發動 51% 攻擊；如果參與率提高到 40% 則需要八個。另外礦池、交易所也不能將所有資本投入攻擊中，因為他們需要保留部分金錢來應付客戶。

再加上在權益證明機制中，組成的礦池的動機是較低的，因為這會需要較高的信任成本 - 雖然礦池不偷錢，但是可以假裝被駭去觸發刪砍條件而導致資本全被沒收，同時扮成檢舉者領檢舉獎金。不過另一方面，即便需要信任對方，不需要自己跑一個 full node 就能用自己的錢賺利潤仍是很有吸引力的。總之，中心化和去中心化間的平衡需要經驗累積，也只有等到系統真的上線一段時間了才有辦法得到答案。但配上 sharding 之後，我們預計會更進一步降低中心化，因為 (i)需要考量的變化更少且 (ii)在 sharding 模型中，驗證交易的負擔和所投入的資本成正比，所以並不會因為組成礦池而節省成本支出。

最後一點是，中心化在權益證明機制中比其在工作量證明機制中的負面影響更小，因為從 51% 攻擊中復原容易且便宜多了，也不需要換新的挖礦演算法。

### 權益證明機制 能被用在私有鏈或聯盟鏈嗎？

一般來說是可以的。任何權益證明機制演算法都可以被私有鏈或聯盟鏈用做一個共識演算法。唯一不同是成為驗證者的方式：一開始會由一群大家同意且信任的使用者成為驗證者，接著再由這群驗證者透過投票去加入新的驗證者。